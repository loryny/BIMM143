---
title: "Machine Learning 1"
author: "Loryn Young"
date: "2/8/2022"
output: pdf_document
---

```{r}
tmp <- c( rnorm(30, -3), rnorm(30, 3) )
x <- cbind(x=tmp, y=rev(tmp))
x
plot(x)
```
```{r}
k <- kmeans(x, centers = 2, nstart=20)
k
```

> Q. How many rows and columns are in your new data frame named x? What R functions could you use to answer this question? 

> Q. How many points are in each cluster?

```{r}
k$size
```

> Q. How do we get to the cluster membership/assignment? 

```{r}
k$cluster
```

> Q. What about cluster centers? 

```{r}
k$centers
```

Now we got to the main results, let's use them to plot our data with the kmeans result 

```{r}
plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15)
```

We will cluster the same data 'x' with the 'hclust()'. In this case, 'hclust()' requires a distance matrix as 

```{r}
hc  <- hclust(dist(x))
hc
```
Let's plot our hclust result

```{r}
plot(hc)
```

To get our cluster membership vector we need to "cut" the tree with the 'cutree()'

```{r}
grps <- cutree(hc, h=8)
grps
```

Now plot our data with the hclust() results 
```{r}
plot(x, col=grps)
```

# Principal Component Analysis (PCA)

## PCA of UK food data

Read data from website and try a few visualizations 

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names=1)
x
```
> Q. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

```{r}
barplot(as.matrix(x) )
```

```{r}
cols <- rainbow(nrow(x))
barplot( as.matrix(x), col=cols)
```

```{r}
barplot( as.matrix(x), col=cols, beside=TRUE)
```

> Q. Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=cols)
```

PCA to the rescue
The main base R PCA function is called 'prcomp()' and we will need to give it the transpose of our input data 

```{r}

pca <- prcomp( t(x) )
```

```{r}
attributes(pca)
```

To make our new PCA plot (aka PCA score plot) we access 'pca$x'

```{r}
plot(pca$x[,1], pca$x[,2])
text(pca$x[,1], pca$x[,2], colnames(x))
```

color up the plot 

```{r}
country_cols <- c("orange", "red", "blue", "green")
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
text(pca$x[,1], pca$x[,2], colnames(x), col=country_cols)
```

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
z <- summary(pca)
z$importance
```
```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```
```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```
> Q. Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2 )
```
Sugars are associated with a large positive loading score that effectively "push" N, whereas soft drinks have a high negative score to push the countries to the left side of the plot

```{r}
biplot(pca)
```

# PCA of RNA-seq data 

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```
> Q. How many genes and samples are in this data set?

```{r}
pca <- prcomp(t(rna.data), scale=TRUE)
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```


```{r}
prcomp( t(rna.data) )
summary(pca)
```

Do our PCA plot of this RNA-Seq data 

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
text(pca$x[,1], pca$x[,2], colnames(rna.data))
```

```{r}
plot(pca, main="Quick scree plot")
```

```{r}
## Variance captured per PC 
pca.var <- pca$sdev^2

## Percent variance is often more informative to look at 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

```{r}
barplot(pca.var.per, main="Scree Plot", 
        names.arg = paste0("PC", 1:10),
        xlab="Principal Component", ylab="Percent Variation")
```

```{r}
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)"))

text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))

```

```{r}
library(ggplot2)

df <- as.data.frame(pca$x)

ggplot(df) + 
  aes(PC1, PC2) + 
  geom_point()
```

```{r}
df$samples <- colnames(rna.data) 
df$condition <- substr(colnames(rna.data),1,2)

p <- ggplot(df) + 
        aes(PC1, PC2, label=samples, col=condition) + 
        geom_label(show.legend = FALSE)
p
```

```{r}
p + labs(title="PCA of RNASeq Data",
       subtitle = "PC1 clealy seperates wild-type from knock-out samples",
       x=paste0("PC1 (", pca.var.per[1], "%)"),
       y=paste0("PC2 (", pca.var.per[2], "%)"),
       caption="BIMM143 example data") +
     theme_bw()
```

```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

